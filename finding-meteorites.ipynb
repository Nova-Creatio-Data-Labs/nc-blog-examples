{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Clean Up Your Data\n",
    "## Example: Where to look for Meteorites in the USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you have some fresh data, which you are sure contains useful insights. But now what?\n",
    "\n",
    "While every dataset will need its own specific cleaning steps, we follow a general procedure, no matter the data we are cleaning. I will use as an example the Meteorite Landings dataset provided by the Meteorical Society, accessible at the NASA Open Data Portal (this webpage) [https://data.nasa.gov/Space-Science/Meteorite-Landings/ak9y-cwf9]. I will data clean using Python 3.9 in Microsoft Visual Studio Code. \n",
    "\n",
    "In any data cleaning exercise, we follow these steps:\n",
    "\n",
    "### Step 1: Define your initial goal.\n",
    "\n",
    "Carefully define what you want from the data. You may revise it, but at first, think about what you want to accomplish. For the Meteorite Landings data, we want to find where we can most readily find meteorites in the continental USA. Assuming that meteorite landings are spread evenly across the surface of the Earth, this would correspond to the area with the *least* density of meteorites which have been found.\n",
    "\n",
    "### Step 2: Summarize your Dataset\n",
    "\n",
    "This basic step involves doing very basic perusals of your data. How many data entries does the data contain? How many data fields? What does each data field contain? \n",
    "\n",
    "Pandas is our favorite library for answering these basic questions, because of its ease of use and many handy methods for data exploration. If you haven't already, create a virtual environment in your project directory, activate it, and then install pandas.\n",
    "\n",
    "* python 3.9 -m venv .venv *(Create a Virtual Environment in your current directory)*\n",
    "* .venv\\Scripts\\Activate.ps1 *(activate it in your PowerShell terminal)*\n",
    "* pip install pandas *(install pandas!)*\n",
    "\n",
    "Now open your data and inspect it using. I'll do this for Meteorite Landings as an example. This data is in CSV, handy to read using pandas -- pandas will read the CSV and convert into a tabular dataframe. I will inspect the summary information of this dataframe and then inspect a sample using two handy dataframe methods - sample(), and the atttribute .style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45716 entries, 0 to 45715\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   name         45716 non-null  object \n",
      " 1   id           45716 non-null  int64  \n",
      " 2   nametype     45716 non-null  object \n",
      " 3   recclass     45716 non-null  object \n",
      " 4   mass (g)     45585 non-null  float64\n",
      " 5   fall         45716 non-null  object \n",
      " 6   year         45425 non-null  float64\n",
      " 7   reclat       38401 non-null  float64\n",
      " 8   reclong      38401 non-null  float64\n",
      " 9   GeoLocation  38401 non-null  object \n",
      " 10  States       1659 non-null   float64\n",
      " 11  Counties     1659 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(5)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meteorite_data = pd.read_csv('example-datasets/Meteorite_Landings.csv')\n",
    "\n",
    "meteorite_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is 4.2 MB in size, with 11 fields composed of a mix of strings and float values. \n",
    "\n",
    "#### Data Summary\n",
    "Summarizing this work, we can see that this dataset contains a list of known meteorites which have struck the earth, along with their latitude, longitude, mass, and year of observation. \n",
    "\n",
    "### Step 4: Data Dictionary Review and Key Variable identification\n",
    "**Goal** Understand all of the data in your dataset, and identify key variables that you will use in your analysis, and which you *might* use in your analysis. \n",
    "\n",
    "Now, review the fields, line by line, as they appear in the dataset. Also peruse the available documentation, to help understand each field. Once you have done that, give a line-by-line summary of what each data field describes and the data it contains. \n",
    "\n",
    "It's always important to review the \"real\" data when you do this, rather than just field names. So let's look at a random sample of 5 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b5edf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5edf_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_b5edf_level0_col1\" class=\"col_heading level0 col1\" >id</th>\n",
       "      <th id=\"T_b5edf_level0_col2\" class=\"col_heading level0 col2\" >nametype</th>\n",
       "      <th id=\"T_b5edf_level0_col3\" class=\"col_heading level0 col3\" >recclass</th>\n",
       "      <th id=\"T_b5edf_level0_col4\" class=\"col_heading level0 col4\" >mass (g)</th>\n",
       "      <th id=\"T_b5edf_level0_col5\" class=\"col_heading level0 col5\" >fall</th>\n",
       "      <th id=\"T_b5edf_level0_col6\" class=\"col_heading level0 col6\" >year</th>\n",
       "      <th id=\"T_b5edf_level0_col7\" class=\"col_heading level0 col7\" >reclat</th>\n",
       "      <th id=\"T_b5edf_level0_col8\" class=\"col_heading level0 col8\" >reclong</th>\n",
       "      <th id=\"T_b5edf_level0_col9\" class=\"col_heading level0 col9\" >GeoLocation</th>\n",
       "      <th id=\"T_b5edf_level0_col10\" class=\"col_heading level0 col10\" >States</th>\n",
       "      <th id=\"T_b5edf_level0_col11\" class=\"col_heading level0 col11\" >Counties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5edf_level0_row0\" class=\"row_heading level0 row0\" >43611</th>\n",
       "      <td id=\"T_b5edf_row0_col0\" class=\"data row0 col0\" >Yamato 980172</td>\n",
       "      <td id=\"T_b5edf_row0_col1\" class=\"data row0 col1\" >36798</td>\n",
       "      <td id=\"T_b5edf_row0_col2\" class=\"data row0 col2\" >Valid</td>\n",
       "      <td id=\"T_b5edf_row0_col3\" class=\"data row0 col3\" >L6</td>\n",
       "      <td id=\"T_b5edf_row0_col4\" class=\"data row0 col4\" >480.630000</td>\n",
       "      <td id=\"T_b5edf_row0_col5\" class=\"data row0 col5\" >Found</td>\n",
       "      <td id=\"T_b5edf_row0_col6\" class=\"data row0 col6\" >1998.000000</td>\n",
       "      <td id=\"T_b5edf_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_b5edf_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_b5edf_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_b5edf_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_b5edf_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5edf_level0_row1\" class=\"row_heading level0 row1\" >20291</th>\n",
       "      <td id=\"T_b5edf_row1_col0\" class=\"data row1 col0\" >Lewis Cliff 86383</td>\n",
       "      <td id=\"T_b5edf_row1_col1\" class=\"data row1 col1\" >13314</td>\n",
       "      <td id=\"T_b5edf_row1_col2\" class=\"data row1 col2\" >Valid</td>\n",
       "      <td id=\"T_b5edf_row1_col3\" class=\"data row1 col3\" >H5</td>\n",
       "      <td id=\"T_b5edf_row1_col4\" class=\"data row1 col4\" >10.500000</td>\n",
       "      <td id=\"T_b5edf_row1_col5\" class=\"data row1 col5\" >Found</td>\n",
       "      <td id=\"T_b5edf_row1_col6\" class=\"data row1 col6\" >1986.000000</td>\n",
       "      <td id=\"T_b5edf_row1_col7\" class=\"data row1 col7\" >-84.273730</td>\n",
       "      <td id=\"T_b5edf_row1_col8\" class=\"data row1 col8\" >161.693170</td>\n",
       "      <td id=\"T_b5edf_row1_col9\" class=\"data row1 col9\" >(-84.27373, 161.69317)</td>\n",
       "      <td id=\"T_b5edf_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_b5edf_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5edf_level0_row2\" class=\"row_heading level0 row2\" >11749</th>\n",
       "      <td id=\"T_b5edf_row2_col0\" class=\"data row2 col0\" >Fort Pierre</td>\n",
       "      <td id=\"T_b5edf_row2_col1\" class=\"data row2 col1\" >10167</td>\n",
       "      <td id=\"T_b5edf_row2_col2\" class=\"data row2 col2\" >Valid</td>\n",
       "      <td id=\"T_b5edf_row2_col3\" class=\"data row2 col3\" >Iron, IIIAB</td>\n",
       "      <td id=\"T_b5edf_row2_col4\" class=\"data row2 col4\" >15900.000000</td>\n",
       "      <td id=\"T_b5edf_row2_col5\" class=\"data row2 col5\" >Found</td>\n",
       "      <td id=\"T_b5edf_row2_col6\" class=\"data row2 col6\" >1856.000000</td>\n",
       "      <td id=\"T_b5edf_row2_col7\" class=\"data row2 col7\" >44.350000</td>\n",
       "      <td id=\"T_b5edf_row2_col8\" class=\"data row2 col8\" >-100.383330</td>\n",
       "      <td id=\"T_b5edf_row2_col9\" class=\"data row2 col9\" >(44.35, -100.38333)</td>\n",
       "      <td id=\"T_b5edf_row2_col10\" class=\"data row2 col10\" >21.000000</td>\n",
       "      <td id=\"T_b5edf_row2_col11\" class=\"data row2 col11\" >2732.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5edf_level0_row3\" class=\"row_heading level0 row3\" >22696</th>\n",
       "      <td id=\"T_b5edf_row3_col0\" class=\"data row3 col0\" >MacAlpine Hills 87314</td>\n",
       "      <td id=\"T_b5edf_row3_col1\" class=\"data row3 col1\" >15257</td>\n",
       "      <td id=\"T_b5edf_row3_col2\" class=\"data row3 col2\" >Valid</td>\n",
       "      <td id=\"T_b5edf_row3_col3\" class=\"data row3 col3\" >L6</td>\n",
       "      <td id=\"T_b5edf_row3_col4\" class=\"data row3 col4\" >319.300000</td>\n",
       "      <td id=\"T_b5edf_row3_col5\" class=\"data row3 col5\" >Found</td>\n",
       "      <td id=\"T_b5edf_row3_col6\" class=\"data row3 col6\" >1987.000000</td>\n",
       "      <td id=\"T_b5edf_row3_col7\" class=\"data row3 col7\" >-84.216670</td>\n",
       "      <td id=\"T_b5edf_row3_col8\" class=\"data row3 col8\" >160.500000</td>\n",
       "      <td id=\"T_b5edf_row3_col9\" class=\"data row3 col9\" >(-84.21667, 160.5)</td>\n",
       "      <td id=\"T_b5edf_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_b5edf_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5edf_level0_row4\" class=\"row_heading level0 row4\" >10011</th>\n",
       "      <td id=\"T_b5edf_row4_col0\" class=\"data row4 col0\" >Elephant Moraine 87857</td>\n",
       "      <td id=\"T_b5edf_row4_col1\" class=\"data row4 col1\" >8407</td>\n",
       "      <td id=\"T_b5edf_row4_col2\" class=\"data row4 col2\" >Valid</td>\n",
       "      <td id=\"T_b5edf_row4_col3\" class=\"data row4 col3\" >L6</td>\n",
       "      <td id=\"T_b5edf_row4_col4\" class=\"data row4 col4\" >22.600000</td>\n",
       "      <td id=\"T_b5edf_row4_col5\" class=\"data row4 col5\" >Found</td>\n",
       "      <td id=\"T_b5edf_row4_col6\" class=\"data row4 col6\" >1987.000000</td>\n",
       "      <td id=\"T_b5edf_row4_col7\" class=\"data row4 col7\" >-76.282780</td>\n",
       "      <td id=\"T_b5edf_row4_col8\" class=\"data row4 col8\" >156.453910</td>\n",
       "      <td id=\"T_b5edf_row4_col9\" class=\"data row4 col9\" >(-76.28278, 156.45391)</td>\n",
       "      <td id=\"T_b5edf_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_b5edf_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21c5dd8bfa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteorite_data.sample(5).style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a short summary of the fields, based on what we can observe, and from what the (very limited) documentation provides:\n",
    "\n",
    "1) **name** is just a verbal description. This won't be much use in any analysis.\n",
    "2) **id** appears to be a unique number for each field - pretty handy.\n",
    "3) **nametype** it is not clear what this means, but if you look at the (webpage) [https://data.nasa.gov/Space-Science/Meteorite-Landings/gh4g-9sfh] it says \"Under NameType, 'valid' is for most meteorites and 'relict' are for objects that were once meteorites but are now highly altered by weathering on Earth.\" This field doesn't appear that useful to us.\n",
    "4) **recclass** is ambiguous, and unfortunately the documentation doesn't describe what it means. (This is a problem data scientists have to live with - badly documented data.)\n",
    "5) **mass** is the size of the meteorite.\n",
    "6) **fall** is always either \"Found\" or \"Fell\" - telling us whether the meteorite was observed or actually found.\n",
    "7) **year** is the year of being found.\n",
    "8) **reclat**, **reclong**, and **GeoLocation** are all redundant fields expressing the location of the observation.\n",
    "9) **States** and **Counties** are also ambiguous fields, composed of many numbers, and the documentation does not describe it any better.\n",
    "\n",
    "Since we are interested simply in the spatial density of meteorite landings, our key variables are **reclat**, **reclong**, and **GeoLocation**. We also might use **year**, **id**, and **mass**, since these are interesting variables which could affect our analysis in ways we cannot yet anticipate. The variable **name** will also be useful as an identifier while we review the data.\n",
    "\n",
    "Since we don't even understand what **nametype**, **reclass**, **States**, or **Counties** mean, we can't use them. \n",
    "\n",
    "It is also very hard to see how we will use **fall**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Explore your Data, Clean your Data, Explore your Data\n",
    "Now begins a step with an end goal of preparing your data for the final analysis you which to do. This is generally an iterative process, where you first explore the data, first to find obvious issues needing correction, like:\n",
    "\n",
    "* Formatting problems in your data needing correction.\n",
    "* Standardization of fields to single, comparable units of a single comparable data type. \n",
    "* Blank or Null values, especially in your key variables, which must be dropped.\n",
    "\n",
    "You should also apply any filters to focus on the data points you are interested in.\n",
    "\n",
    "You can then do some more advanced exploration and cleaning. You should review the characteristics of your key variables, including statistics like median, maximum, minimum, but also other characteristics like clusters and intervariable correlations. This will help you identify outliers in your dataset which might need correction. \n",
    "\n",
    "There is no single recipe for how you find this information, but it will involve calculating statistics, reviewing histograms, making maps, and using other analysis techniques.\n",
    "\n",
    "And once this exploration is complete, you apply various cleaning steps -- whether it be dropping Null values, correcting units, or otherwise. \n",
    "\n",
    "I will do this step by step for the example applied to the Meteorite Landings dataset.\n",
    "\n",
    "#### Reviewing reclat, reclon, Geolocation rows with NaN\n",
    "From visual inspection of data earlier, it is clear that many meteorites do not have location data. This makes these rows useless, and so I will drop NaN rows. But what is unclear is - are reclat, reclon, and Geolocation, completely redundant? Are there NaN rows in reclat, reclon, where data is available in Geolocation? We want to maximize the information. Let's review the NaN values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows where reclat is NaN is 7315, and where GeoLocation is NaN is 7315.\n",
      "The number of rows where only one location value is NaN is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14154\\AppData\\Local\\Temp\\ipykernel_22204\\230847687.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  non_overlap_nan = non_overlap_nan.append(meteorite_data[(meteorite_data['reclat'].notna()) & (meteorite_data['GeoLocation'].isna())])\n"
     ]
    }
   ],
   "source": [
    "# Check and compare the number of NaN rows in each field. \n",
    "nan_rec_data=meteorite_data[meteorite_data['reclat'].isna()]\n",
    "nan_geo_data=meteorite_data[meteorite_data['GeoLocation'].isna()]\n",
    "\n",
    "print(f\"The number of rows where reclat is NaN is {len(nan_rec_data)}, and where GeoLocation is NaN is {len(nan_geo_data)}.\")\n",
    "\n",
    "# Now create a dataframe whichi includes any instances where one value is NaN, but the other is not.\n",
    "non_overlap_nan = meteorite_data[(meteorite_data['reclat'].isna()) & (meteorite_data['GeoLocation'].notna())]\n",
    "\n",
    "non_overlap_nan = non_overlap_nan.append(meteorite_data[(meteorite_data['reclat'].notna()) & (meteorite_data['GeoLocation'].isna())])\n",
    "print(f\"The number of rows where only one location value is NaN is {len(non_overlap_nan)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location values of **reclat**, **reclon**, and **GeoLocation** are redundant - so we can drop all NaN values as useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tumber of meteorite strikes in the dataset: 45716.\n",
      "Total tumber of meteorite strikes containing location information: 38401.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total tumber of meteorite strikes in the dataset: {len(meteorite_data)}.\")\n",
    "meteorite_data_c = meteorite_data.dropna(subset='reclat')\n",
    "print(f\"Total tumber of meteorite strikes containing location information: {len(meteorite_data_c)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, filter the strieks to only those in the USA> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d76a85082d2d5441f1e67ca777c84fcc1c822c057c46e5fd26db38a2abfaf23e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
